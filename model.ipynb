{
 "cells": [
  {
   "cell_type": "raw",
   "id": "73cb6f89-0245-42ae-9f4d-be62cadc2d83",
   "metadata": {},
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edb4bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 152,626\n",
      "Model device: cuda:0\n",
      "Model device name: NVIDIA GeForce RTX 5070 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "\n",
    "# Configuration\n",
    "config = HookedTransformerConfig(\n",
    "    n_layers=2,\n",
    "    n_heads=8,\n",
    "    d_model=128,\n",
    "    d_head=16,  # d_model / n_heads\n",
    "    d_mlp=None,  # No MLPs (attention-only)\n",
    "    act_fn=None,  # No activation (no MLPs)\n",
    "    attention_dir=\"causal\",  # Causal attention\n",
    "    attn_only=True,  # Attention-only model\n",
    "    normalization_type=None,  # No LayerNorm for simplicity\n",
    "    d_vocab=50,  # 26 letters + 10 digits + special tokens\n",
    "    n_ctx=60,  # Max sequence length\n",
    "    init_weights=True,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "model = HookedTransformer(config)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "print(f\"Model device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d59195-2df3-4d0c-bf1d-bce5105aa3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    class TrieNode:\n",
    "        def __init__(self):\n",
    "            self.id = None\n",
    "            self.next = {}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.root = self.TrieNode()\n",
    "        self.token_map = {} # Stores mapping of ID to token\n",
    "        self.size = 0\n",
    "\n",
    "    # Adds a new token into the vocabulary\n",
    "    def add_token(self, token):\n",
    "        node = self.root\n",
    "        for c in token:\n",
    "            if c not in node.next:\n",
    "                node.next[c] = self.TrieNode()\n",
    "            node = node.next[c]\n",
    "        if node.id is None:\n",
    "            node.id = self.size\n",
    "            self.token_map[self.size] = token\n",
    "            self.size += 1\n",
    "\n",
    "    # Finds id of longest prefix token of text[start:end], and returns length of token\n",
    "    def longest_prefix_token(self, text, start):\n",
    "        longest_token = None\n",
    "        longest_length = 0\n",
    "        node = self.root\n",
    "        for i in range(start, len(text)):\n",
    "            if text[i] not in node.next:\n",
    "                break\n",
    "            node = node.next[text[i]]\n",
    "            if node.id is not None:\n",
    "                longest_token = node.id\n",
    "                longest_length = i - start + 1\n",
    "        assert longest_token is not None\n",
    "        return longest_token, longest_length\n",
    "\n",
    "    # Converts an id to the corresponding token\n",
    "    def get_token(self, id):\n",
    "        return self.token_map[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0f64205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple character-level tokenizer\n",
    "class CountingTokenizer:\n",
    "    def __init__(self):\n",
    "        # Vocabulary: letters + digits + special tokens\n",
    "        self.vocab = Vocabulary()\n",
    "        chars = list(\"abcdefghijklmnopqrstuvwxyz0123456789\")\n",
    "        special = [\"<PAD>\", \"<BOS>\", \"<EOS>\", \":\", \" \", \"Count\", \"the\", \"letter\", \"in\"]\n",
    "        raw_vocab = special + chars\n",
    "        for token in raw_vocab:\n",
    "            self.vocab.add_token(token)\n",
    "\n",
    "    def encode(self, text, include_lengths = False):\n",
    "        \"\"\"Convert text to token IDs\"\"\"\n",
    "        ids = []\n",
    "        i = 0\n",
    "        while i < len(text):\n",
    "            id, token_length = self.vocab.longest_prefix_token(text, i)\n",
    "            assert id != -1\n",
    "            if include_lengths:\n",
    "                ids.append((id, token_length))\n",
    "            else:\n",
    "                ids.append(id)\n",
    "            i += token_length\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        \"\"\"Convert token IDs to text\"\"\"\n",
    "        return \"\".join([self.vocab.get_token(id) for id in ids])\n",
    "\n",
    "    def apply_bpe(self, words, max_token_length=3):\n",
    "        \"\"\"Adds merge rules based on a list of words for BPE\"\"\"\n",
    "        text = \"\".join([f\"<BOS>{word}<EOS>\" for word in words])\n",
    "        ignore_tokens = [\"<PAD>\", \"<BOS>\", \"<EOS>\", \":\", \" \"]\n",
    "        while True:\n",
    "            encoded = self.encode(text, include_lengths=True)\n",
    "            pairs = {}\n",
    "            merge_pair = ()\n",
    "            for i in range(len(encoded) - 1):\n",
    "                token_pair = encoded[i], encoded[i + 1]\n",
    "                if token_pair[0][1] + token_pair[1][1] > max_token_length:\n",
    "                    continue\n",
    "                if any(self.vocab.get_token(token[0]) in ignore_tokens for token in token_pair):\n",
    "                    continue\n",
    "                pairs[token_pair] = pairs.get(token_pair, 0) + 1\n",
    "                if not merge_pair or pairs[merge_pair] < pairs[token_pair]:\n",
    "                    merge_pair = token_pair\n",
    "            if not merge_pair or pairs[merge_pair] < 2:\n",
    "                break\n",
    "            self.vocab.add_token(\"\".join([self.vocab.get_token(token[0]) for token in merge_pair]))\n",
    "\n",
    "tokenizer = CountingTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fbf56ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Count the letter a in: qhgajcn1\n",
      "Tokens: [5, 4, 6, 4, 7, 4, 9, 4, 8, 3, 4, 25, 16, 15, 9, 18, 11, 22, 36]\n",
      "Question Tokens Decoded: ['Count', ' ', 'the', ' ', 'letter', ' ', 'a', ' ', 'in', ':', ' ', 'q', 'h', 'g', 'a', 'j', 'c', 'n']\n",
      "Question length: 18\n",
      "Answer: 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_counting_question(target_letter='a', multiplicity_range=(1, 2), length_range=(5, 10)):\n",
    "    \"\"\"\n",
    "    Generates a new word based on input parameters and gives the answer to the question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample words with target letter\n",
    "    words_with_target = []\n",
    "    count = random.randint(*multiplicity_range)\n",
    "    \n",
    "    # Generate string with exact count of target letter\n",
    "    chars = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "    chars.remove(target_letter)\n",
    "    \n",
    "    length = random.randint(max(count, length_range[0]), length_range[1])\n",
    "    string_chars = random.choices(chars, k=length - count)\n",
    "    \n",
    "    # Insert target letters\n",
    "    positions = random.sample(range(length), count)\n",
    "    for pos in positions:\n",
    "        string_chars.insert(pos, target_letter)\n",
    "    \n",
    "    input_string = \"\".join(string_chars[:length])\n",
    "    question = f\"Count the letter {target_letter} in: {input_string}\"\n",
    "    answer = str(count)\n",
    "\n",
    "    return question, answer\n",
    "\n",
    "def generate_counting_example(qa, tokenizer=None):\n",
    "    \"\"\"\n",
    "    Generate: \"Count the letter a in: banana\" -> \"3\"\n",
    "    Format: [question tokens] [answer token]\n",
    "    \"\"\"\n",
    "    question, answer = qa\n",
    "    \n",
    "    # Tokenize\n",
    "    question_tokens = tokenizer.encode(question)\n",
    "    question_tokens_decoded = [tokenizer.decode([token]) for token in question_tokens]\n",
    "    answer_token = tokenizer.encode(answer)[0]  # Single digit\n",
    "    \n",
    "    # Combine: question + answer\n",
    "    full_tokens = question_tokens + [answer_token]\n",
    "    \n",
    "    return {\n",
    "        'tokens': full_tokens,\n",
    "        'question_tokens_decoded': question_tokens_decoded,\n",
    "        'question_length': len(question_tokens),  # For loss masking\n",
    "        'answer': int(answer),\n",
    "        'text': question + answer\n",
    "    }\n",
    "\n",
    "# Test\n",
    "tokenizer = CountingTokenizer()\n",
    "qa = generate_counting_question()\n",
    "example = generate_counting_example(qa, tokenizer=tokenizer)\n",
    "print(f\"Text: {example['text']}\")\n",
    "print(f\"Tokens: {example['tokens']}\")\n",
    "print(f\"Question Tokens Decoded: {example['question_tokens_decoded']}\")\n",
    "print(f\"Question length: {example['question_length']}\")\n",
    "print(f\"Answer: {example['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "096c9875-c66d-48e8-8b77-a82023f79280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Pre-Processing Text: <BOS>Count the letter a in: vvbawnvajn<EOS><BOS>Count the letter a in: sxnjiharl<EOS><BOS>Count the letter a in: rhanfb<EOS><BOS>Count the letter a in: paoae<EOS><BOS>Count the letter a in: aamilgus<EOS><BOS>Count the letter a in: sgqnlant<EOS><BOS>Count the letter a in: foxaa<EOS><BOS>Count the letter a in: xchaubpba<EOS><BOS>Count the letter a in: mpeaualz<EOS><BOS>Count the letter a in: leamdssug<EOS>\n",
      "Text: Count the letter a in: aygkohe1\n",
      "Tokens: [5, 4, 6, 4, 7, 4, 9, 4, 8, 3, 4, 9, 33, 15, 19, 23, 16, 13, 36]\n",
      "Question Tokens Decoded: ['Count', ' ', 'the', ' ', 'letter', ' ', 'a', ' ', 'in', ':', ' ', 'a', 'y', 'g', 'k', 'o', 'h', 'e']\n",
      "Question length: 18\n",
      "Answer: 1\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "qas = [generate_counting_question() for i in range(10)]\n",
    "tokenizer = CountingTokenizer()\n",
    "tokenizer.apply_bpe([qa[0] for qa in qas])\n",
    "qa = generate_counting_question()\n",
    "example = generate_counting_example(qa, tokenizer=tokenizer)\n",
    "print(f\"Sample Pre-Processing Text: {\"\".join([f\"<BOS>{qa[0]}<EOS>\" for qa in qas])}\")\n",
    "print(f\"Text: {example['text']}\")\n",
    "print(f\"Tokens: {example['tokens']}\")\n",
    "print(f\"Question Tokens Decoded: {example['question_tokens_decoded']}\")\n",
    "print(f\"Question length: {example['question_length']}\")\n",
    "print(f\"Answer: {example['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a0f8bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "class CountingDataset(Dataset):\n",
    "    def __init__(self, n_examples=50000, difficulty='easy', tokenizer=None, allow_bpe=True, train_bpe=True):\n",
    "        \"\"\"\n",
    "        difficulty: 'easy', 'bpe-hard', 'mult-hard', etc.\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.examples = []\n",
    "\n",
    "        use_bpe = False\n",
    "        # Set parameters based on difficulty\n",
    "        if difficulty == 'easy':\n",
    "            mult_range = (1, 2)\n",
    "            len_range = (5, 10)\n",
    "        elif difficulty == 'bpe-hard':\n",
    "            mult_range = (1, 2)\n",
    "            len_range = (5, 10)\n",
    "            use_bpe = True\n",
    "        elif difficulty == 'mult-hard':\n",
    "            mult_range = (3, 10)\n",
    "            len_range = (5, 10)\n",
    "        elif difficulty == 'length-hard':\n",
    "            mult_range = (1, 2)\n",
    "            len_range = (20, 50)\n",
    "        elif difficulty == 'all-hard':\n",
    "            mult_range = (3, 10)\n",
    "            len_range = (20, 50)\n",
    "            use_bpe = True\n",
    "        elif difficulty == 'mixed':\n",
    "            mult_range = (1,10)\n",
    "            len_range = (5, 50)\n",
    "            use_bpe = True\n",
    "        else:\n",
    "            assert False\n",
    "        \n",
    "        # Generate basic words\n",
    "        target_letters = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "        qas = []\n",
    "        for _ in range(n_examples):\n",
    "            target = random.choice(target_letters)\n",
    "            qa = generate_counting_question(\n",
    "                target_letter=target,\n",
    "                multiplicity_range=mult_range,\n",
    "                length_range=len_range,\n",
    "            )\n",
    "            qas.append(qa)\n",
    "\n",
    "        # Add basic words to the vocabulary if we are applying BPE\n",
    "        if use_bpe and allow_bpe and train_bpe:\n",
    "            tokenizer.apply_bpe([qa[0] for qa in qas])\n",
    "\n",
    "        # Generate the full questions and examples\n",
    "        basic_tokenizer = CountingTokenizer()\n",
    "        if difficulty == \"mixed\":\n",
    "            bpe_set = random.sample(range(len(qas)), len(qas) // 2)\n",
    "        else:\n",
    "            bpe_set = range(len(qas))\n",
    "        for i in range(len(qas)):\n",
    "            example = generate_counting_example(\n",
    "                qas[i],\n",
    "                tokenizer=tokenizer if i in bpe_set else basic_tokenizer\n",
    "            )\n",
    "            self.examples.append(example)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "def collate_fn(batch, pad_id=0, max_len=100):\n",
    "    \"\"\"Pad sequences to same length\"\"\"\n",
    "    # Pad tokens\n",
    "    tokens = [ex['tokens'] for ex in batch]\n",
    "    max_batch_len = min(max(len(t) for t in tokens), max_len)\n",
    "    \n",
    "    padded_tokens = []\n",
    "    masks = []  # Loss mask: 1 for answer token, 0 elsewhere\n",
    "    \n",
    "    for ex in batch:\n",
    "        seq = ex['tokens'][:max_batch_len]\n",
    "        q_len = min(ex['question_length'], max_batch_len - 1)\n",
    "        \n",
    "        # Pad sequence\n",
    "        padded = seq + [pad_id] * (max_batch_len - len(seq))\n",
    "        padded_tokens.append(padded)\n",
    "        \n",
    "        # Create mask: only compute loss on answer token\n",
    "        mask = [0] * max_batch_len\n",
    "        if q_len < len(seq):  # If answer token exists\n",
    "            mask[q_len] = 1  # Answer is right after question\n",
    "        masks.append(mask)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': torch.tensor(padded_tokens, dtype=torch.long),\n",
    "        'loss_mask': torch.tensor(masks, dtype=torch.float),\n",
    "        'answers': torch.tensor([ex['answer'] for ex in batch], dtype=torch.long)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f38a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "3004\n",
      "45\n",
      "45\n",
      "3588\n",
      "3785\n",
      "Input shape: torch.Size([64, 17])\n",
      "Mask shape: torch.Size([64, 17])\n",
      "Example tokens: tensor([   5,    4,    6,    4,    7,    4,   29,    4,    8,    3,    4,  214,\n",
      "        1195,   37,    0,    0,    0])\n",
      "Example mask: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Create dataloaders\n",
    "train_dataset_names = [\"easy\", \"bpe-hard\", \"mult-hard\", \"length-hard\", \"all-hard\"]\n",
    "GENERATE_NEW_TRAINING_DATA = False # IMPORTANT: Set this to True only if you want to generate new datasets\n",
    "\n",
    "# Training dataloaders\n",
    "train_datasets = {}\n",
    "train_loaders = {}\n",
    "train_tokenizers = {}\n",
    "for name in train_dataset_names:\n",
    "    if GENERATE_NEW_TRAINING_DATA:\n",
    "        train_tokenizers[name] = CountingTokenizer()\n",
    "        train_datasets[name] = CountingDataset(n_examples=20000, difficulty=name, tokenizer=train_tokenizers[name])\n",
    "        with open(f\"train-{name}-dataset.pkl\", \"wb\") as f:\n",
    "            pickle.dump(train_datasets[name], f)\n",
    "        with open(f\"train-{name}-tokenizer.pkl\", \"wb\") as f:\n",
    "            pickle.dump(train_tokenizers[name], f)\n",
    "    else:\n",
    "        with open(f\"train-{name}-dataset.pkl\", \"rb\") as f:\n",
    "            train_datasets[name] = pickle.load(f)\n",
    "        with open(f\"train-{name}-tokenizer.pkl\", \"rb\") as f:\n",
    "            train_tokenizers[name] = pickle.load(f)\n",
    "            print(train_tokenizers[name].vocab.size)\n",
    "    train_loaders[name] = DataLoader(train_datasets[name], batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Test batch\n",
    "batch = next(iter(train_loaders[\"bpe-hard\"]))\n",
    "print(f\"Input shape: {batch['input_ids'].shape}\")\n",
    "print(f\"Mask shape: {batch['loss_mask'].shape}\")\n",
    "print(f\"Example tokens: {batch['input_ids'][0]}\")\n",
    "print(f\"Example mask: {batch['loss_mask'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5241ff67-7c6a-4c23-b58f-2f1ca79e73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_NEW_TESTING_DATA = True # IMPORTANT: Set this to True only if you want to generate new datasets\n",
    "\n",
    "# Testing dataloaders\n",
    "test_dataset_names = [\"easy\", \"bpe-hard\", \"mult-hard\", \"length-hard\", \"all-hard\"]\n",
    "test_datasets = {}\n",
    "test_tokenizers = {}\n",
    "for name in test_dataset_names:\n",
    "    if GENERATE_NEW_TESTING_DATA:\n",
    "        test_datasets[name] = CountingDataset(n_examples=2000, difficulty=name, tokenizer=train_tokenizers[name], allow_bpe=True, train_bpe=False)\n",
    "        with open(f\"test-{name}-dataset.pkl\", \"wb\") as f:\n",
    "            pickle.dump(test_datasets[name], f)\n",
    "    else:\n",
    "        with open(f\"test-{name}-dataset.pkl\", \"rb\") as f:\n",
    "            test_datasets[name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3fa2db8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train model for easy with vocab size 45\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 313/313 [00:02<00:00, 121.81it/s, loss=0.704, acc=0.504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.7856, Acc=0.5038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 313/313 [00:02<00:00, 129.98it/s, loss=0.69, acc=0.498] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=0.7016, Acc=0.4978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 313/313 [00:02<00:00, 138.41it/s, loss=0.691, acc=0.502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.6968, Acc=0.5020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 313/313 [00:02<00:00, 135.83it/s, loss=0.66, acc=0.523] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.6940, Acc=0.5229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 313/313 [00:02<00:00, 136.52it/s, loss=0.647, acc=0.564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.6820, Acc=0.5636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 313/313 [00:02<00:00, 134.49it/s, loss=0.665, acc=0.587]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.6714, Acc=0.5875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 313/313 [00:02<00:00, 133.82it/s, loss=0.609, acc=0.631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.6396, Acc=0.6309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 313/313 [00:02<00:00, 133.10it/s, loss=0.474, acc=0.717]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.5494, Acc=0.7167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 313/313 [00:02<00:00, 134.51it/s, loss=0.137, acc=0.881] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.2795, Acc=0.8811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 313/313 [00:02<00:00, 122.21it/s, loss=0.0129, acc=0.983] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.0560, Acc=0.9834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 313/313 [00:02<00:00, 125.73it/s, loss=0.00197, acc=0.992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.0236, Acc=0.9923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 313/313 [00:02<00:00, 123.51it/s, loss=0.0154, acc=0.998]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.0093, Acc=0.9977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 313/313 [00:02<00:00, 121.37it/s, loss=0.00379, acc=0.999] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.0043, Acc=0.9993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 313/313 [00:02<00:00, 123.46it/s, loss=0.000371, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.0018, Acc=0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 313/313 [00:02<00:00, 126.64it/s, loss=0.000242, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.0013, Acc=0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 313/313 [00:02<00:00, 129.27it/s, loss=4.61e-5, acc=1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.0006, Acc=1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 313/313 [00:02<00:00, 128.95it/s, loss=0.00044, acc=1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.0005, Acc=0.9999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 313/313 [00:02<00:00, 123.90it/s, loss=0.000134, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.0004, Acc=1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 313/313 [00:02<00:00, 123.10it/s, loss=0.00054, acc=1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.0004, Acc=1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 313/313 [00:02<00:00, 127.68it/s, loss=0.00049, acc=1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.0003, Acc=1.0000\n",
      "Starting to train model for bpe-hard with vocab size 3004\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 313/313 [00:02<00:00, 128.14it/s, loss=0.68, acc=0.503] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.9713, Acc=0.5033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 313/313 [00:02<00:00, 130.72it/s, loss=0.735, acc=0.559]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=0.6831, Acc=0.5591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 313/313 [00:02<00:00, 131.71it/s, loss=0.67, acc=0.595] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.6579, Acc=0.5950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 313/313 [00:02<00:00, 127.79it/s, loss=0.621, acc=0.632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.6190, Acc=0.6315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 313/313 [00:02<00:00, 121.50it/s, loss=0.556, acc=0.67] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.5742, Acc=0.6702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 313/313 [00:02<00:00, 124.44it/s, loss=0.511, acc=0.7]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.5350, Acc=0.6998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 313/313 [00:02<00:00, 128.73it/s, loss=0.539, acc=0.732]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.4929, Acc=0.7317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 313/313 [00:02<00:00, 133.97it/s, loss=0.456, acc=0.766]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.4457, Acc=0.7661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 313/313 [00:02<00:00, 134.91it/s, loss=0.51, acc=0.798] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.3928, Acc=0.7978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 313/313 [00:02<00:00, 134.29it/s, loss=0.495, acc=0.831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.3403, Acc=0.8308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 313/313 [00:02<00:00, 132.11it/s, loss=0.645, acc=0.857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.2932, Acc=0.8566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 313/313 [00:02<00:00, 133.56it/s, loss=0.238, acc=0.878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.2496, Acc=0.8782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 313/313 [00:02<00:00, 131.43it/s, loss=0.742, acc=0.899]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.2122, Acc=0.8994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 313/313 [00:02<00:00, 132.80it/s, loss=0.13, acc=0.917]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.1777, Acc=0.9169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 313/313 [00:02<00:00, 131.44it/s, loss=0.0978, acc=0.934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.1487, Acc=0.9343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 313/313 [00:02<00:00, 134.17it/s, loss=0.135, acc=0.947] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.1229, Acc=0.9468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 313/313 [00:02<00:00, 131.56it/s, loss=0.142, acc=0.956] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.1055, Acc=0.9556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 313/313 [00:02<00:00, 134.10it/s, loss=0.0303, acc=0.962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.0933, Acc=0.9620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 313/313 [00:02<00:00, 133.04it/s, loss=0.0871, acc=0.966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.0863, Acc=0.9662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 313/313 [00:02<00:00, 134.22it/s, loss=0.0639, acc=0.968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.0827, Acc=0.9679\n",
      "Starting to train model for mult-hard with vocab size 45\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 313/313 [00:02<00:00, 131.74it/s, loss=1.69, acc=0.25] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=1.9272, Acc=0.2501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 313/313 [00:02<00:00, 134.93it/s, loss=1.28, acc=0.311]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=1.6745, Acc=0.3111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 313/313 [00:02<00:00, 133.98it/s, loss=0.696, acc=0.585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.9569, Acc=0.5845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 313/313 [00:02<00:00, 133.51it/s, loss=0.634, acc=0.696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.6973, Acc=0.6960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 313/313 [00:02<00:00, 132.57it/s, loss=0.298, acc=0.748]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.5825, Acc=0.7479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 313/313 [00:02<00:00, 132.06it/s, loss=0.484, acc=0.772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.5297, Acc=0.7721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 313/313 [00:02<00:00, 132.89it/s, loss=0.393, acc=0.8]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.4697, Acc=0.8000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 313/313 [00:02<00:00, 134.22it/s, loss=0.748, acc=0.822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.4187, Acc=0.8224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 313/313 [00:02<00:00, 134.19it/s, loss=0.252, acc=0.835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.3921, Acc=0.8354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 313/313 [00:02<00:00, 135.50it/s, loss=0.485, acc=0.86] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.3406, Acc=0.8600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 313/313 [00:02<00:00, 132.01it/s, loss=0.292, acc=0.876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.3058, Acc=0.8756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 313/313 [00:02<00:00, 132.82it/s, loss=0.217, acc=0.891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.2716, Acc=0.8908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 313/313 [00:02<00:00, 133.41it/s, loss=0.161, acc=0.912] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.2247, Acc=0.9122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 313/313 [00:02<00:00, 134.60it/s, loss=0.207, acc=0.927] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.1908, Acc=0.9274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 313/313 [00:02<00:00, 134.18it/s, loss=0.134, acc=0.941] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.1590, Acc=0.9411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 313/313 [00:02<00:00, 130.32it/s, loss=0.0754, acc=0.953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.1327, Acc=0.9526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 313/313 [00:02<00:00, 132.72it/s, loss=0.116, acc=0.96]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.1140, Acc=0.9604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 313/313 [00:02<00:00, 133.36it/s, loss=0.123, acc=0.965] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.1024, Acc=0.9650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 313/313 [00:02<00:00, 134.52it/s, loss=0.0933, acc=0.969]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.0940, Acc=0.9689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 313/313 [00:02<00:00, 133.34it/s, loss=0.187, acc=0.97]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.0901, Acc=0.9698\n",
      "Starting to train model for length-hard with vocab size 45\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 313/313 [00:02<00:00, 124.38it/s, loss=0.692, acc=0.494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.7961, Acc=0.4942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 313/313 [00:02<00:00, 125.89it/s, loss=0.697, acc=0.506]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=0.6967, Acc=0.5058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 313/313 [00:02<00:00, 126.87it/s, loss=0.679, acc=0.507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.6977, Acc=0.5068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 313/313 [00:02<00:00, 127.85it/s, loss=0.689, acc=0.51] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.6963, Acc=0.5100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 313/313 [00:02<00:00, 127.14it/s, loss=0.682, acc=0.505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.6967, Acc=0.5053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 313/313 [00:02<00:00, 126.64it/s, loss=0.704, acc=0.51] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.6948, Acc=0.5105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 313/313 [00:02<00:00, 126.25it/s, loss=0.683, acc=0.511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.6947, Acc=0.5109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 313/313 [00:02<00:00, 126.43it/s, loss=0.694, acc=0.511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.6947, Acc=0.5111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 313/313 [00:02<00:00, 125.98it/s, loss=0.695, acc=0.513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.6933, Acc=0.5131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 313/313 [00:02<00:00, 126.80it/s, loss=0.697, acc=0.52] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.6920, Acc=0.5197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 313/313 [00:02<00:00, 126.34it/s, loss=0.697, acc=0.528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.6908, Acc=0.5278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 313/313 [00:02<00:00, 125.29it/s, loss=0.712, acc=0.531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.6892, Acc=0.5305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 313/313 [00:02<00:00, 126.84it/s, loss=0.697, acc=0.537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.6873, Acc=0.5374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 313/313 [00:02<00:00, 127.18it/s, loss=0.672, acc=0.541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.6854, Acc=0.5406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 313/313 [00:02<00:00, 128.52it/s, loss=0.691, acc=0.548]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.6829, Acc=0.5479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 313/313 [00:02<00:00, 125.82it/s, loss=0.71, acc=0.552] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.6812, Acc=0.5524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 313/313 [00:02<00:00, 127.72it/s, loss=0.642, acc=0.555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.6798, Acc=0.5547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 313/313 [00:02<00:00, 125.73it/s, loss=0.688, acc=0.557]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.6789, Acc=0.5572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 313/313 [00:02<00:00, 125.79it/s, loss=0.637, acc=0.561]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.6779, Acc=0.5606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 313/313 [00:02<00:00, 126.68it/s, loss=0.693, acc=0.563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.6777, Acc=0.5631\n",
      "Starting to train model for all-hard with vocab size 3588\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 313/313 [00:02<00:00, 128.00it/s, loss=2.05, acc=0.134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=2.3690, Acc=0.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 313/313 [00:02<00:00, 131.42it/s, loss=2.02, acc=0.196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=2.0118, Acc=0.1965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 313/313 [00:02<00:00, 128.26it/s, loss=1.91, acc=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=1.8939, Acc=0.2620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 313/313 [00:02<00:00, 131.25it/s, loss=1.75, acc=0.319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=1.7733, Acc=0.3190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 313/313 [00:02<00:00, 130.21it/s, loss=1.62, acc=0.396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=1.5942, Acc=0.3958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 313/313 [00:02<00:00, 130.28it/s, loss=1.67, acc=0.48] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=1.4006, Acc=0.4804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 313/313 [00:02<00:00, 130.66it/s, loss=1.3, acc=0.551]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=1.2213, Acc=0.5513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 313/313 [00:02<00:00, 130.11it/s, loss=0.988, acc=0.617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=1.0552, Acc=0.6167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 313/313 [00:02<00:00, 129.70it/s, loss=0.784, acc=0.677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.9060, Acc=0.6766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 313/313 [00:02<00:00, 130.52it/s, loss=0.762, acc=0.736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.7519, Acc=0.7356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 313/313 [00:02<00:00, 128.49it/s, loss=0.504, acc=0.792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.6059, Acc=0.7920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 313/313 [00:02<00:00, 130.43it/s, loss=0.757, acc=0.845]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.4709, Acc=0.8445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 313/313 [00:02<00:00, 129.59it/s, loss=0.407, acc=0.891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.3518, Acc=0.8908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 313/313 [00:02<00:00, 129.91it/s, loss=0.479, acc=0.92]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.2619, Acc=0.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 313/313 [00:02<00:00, 128.61it/s, loss=0.0586, acc=0.951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.1847, Acc=0.9512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 313/313 [00:02<00:00, 128.09it/s, loss=0.1, acc=0.967]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.1344, Acc=0.9667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 313/313 [00:02<00:00, 129.44it/s, loss=0.116, acc=0.976] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.1035, Acc=0.9762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 313/313 [00:02<00:00, 131.01it/s, loss=0.0778, acc=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.0843, Acc=0.9814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 313/313 [00:02<00:00, 130.44it/s, loss=0.0134, acc=0.984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.0740, Acc=0.9842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 313/313 [00:02<00:00, 128.27it/s, loss=0.149, acc=0.986]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.0694, Acc=0.9857\n",
      "Starting to train model for mixed with vocab size 3785\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████| 313/313 [00:02<00:00, 122.57it/s, loss=2.19, acc=0.188]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=2.4493, Acc=0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████| 313/313 [00:02<00:00, 123.51it/s, loss=2.21, acc=0.205]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=2.1516, Acc=0.2051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████| 313/313 [00:02<00:00, 125.88it/s, loss=1.87, acc=0.227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=2.0724, Acc=0.2271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████| 313/313 [00:02<00:00, 123.63it/s, loss=1.96, acc=0.282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=1.9507, Acc=0.2816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████| 313/313 [00:02<00:00, 122.04it/s, loss=1.7, acc=0.349] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=1.7770, Acc=0.3488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████| 313/313 [00:02<00:00, 125.72it/s, loss=1.38, acc=0.417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=1.5929, Acc=0.4168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████| 313/313 [00:02<00:00, 119.13it/s, loss=1.71, acc=0.473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=1.4428, Acc=0.4726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████| 313/313 [00:02<00:00, 116.60it/s, loss=1.2, acc=0.52]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=1.3206, Acc=0.5198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████| 313/313 [00:02<00:00, 113.98it/s, loss=1.62, acc=0.546] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=1.2382, Acc=0.5464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|██████████| 313/313 [00:02<00:00, 107.90it/s, loss=1.24, acc=0.572] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=1.1692, Acc=0.5717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|██████████| 313/313 [00:02<00:00, 116.68it/s, loss=1.26, acc=0.582] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=1.1321, Acc=0.5816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████| 313/313 [00:02<00:00, 124.69it/s, loss=1.18, acc=0.594] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=1.1008, Acc=0.5936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████| 313/313 [00:02<00:00, 122.93it/s, loss=1.1, acc=0.6]    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=1.0786, Acc=0.5996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|██████████| 313/313 [00:02<00:00, 124.51it/s, loss=1.2, acc=0.605]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=1.0611, Acc=0.6047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████| 313/313 [00:02<00:00, 122.90it/s, loss=0.529, acc=0.611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=1.0473, Acc=0.6108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|██████████| 313/313 [00:02<00:00, 120.53it/s, loss=0.799, acc=0.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=1.0380, Acc=0.6122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|██████████| 313/313 [00:02<00:00, 123.38it/s, loss=0.79, acc=0.616] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=1.0289, Acc=0.6156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|██████████| 313/313 [00:02<00:00, 124.12it/s, loss=1.04, acc=0.618] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=1.0229, Acc=0.6182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|██████████| 313/313 [00:02<00:00, 124.74it/s, loss=0.953, acc=0.619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=1.0182, Acc=0.6194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████| 313/313 [00:02<00:00, 121.85it/s, loss=0.949, acc=0.62] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=1.0153, Acc=0.6203\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "RETRAIN = True # IMPORTANT: Only toggle to True if you want to actually train new models\n",
    "\n",
    "def train_model(model, name, train_loader, n_epochs=10, lr=1e-3, device='cuda'):\n",
    "    \"\"\"\n",
    "    Train with MASKED loss (only on answer token)\n",
    "    \n",
    "    Classification loss: CrossEntropy on vocabulary\n",
    "    (Can also try regression loss on digit value)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "    \n",
    "    # Classification loss (predict token ID)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')  # Per-token loss\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        for batch in pbar:\n",
    "            input_ids = batch['input_ids'].to(device)  # [batch, seq_len]\n",
    "            loss_mask = batch['loss_mask'].to(device)  # [batch, seq_len]\n",
    "            \n",
    "            # Forward pass\n",
    "            # Input: all tokens except last\n",
    "            # Target: all tokens except first (shifted by 1)\n",
    "            logits = model(input_ids[:, :-1])  # [batch, seq_len-1, vocab]\n",
    "            targets = input_ids[:, 1:]  # [batch, seq_len-1]\n",
    "            \n",
    "            # Compute loss\n",
    "            loss_per_token = criterion(\n",
    "                logits.reshape(-1, logits.size(-1)),  # [batch*(seq_len-1), vocab]\n",
    "                targets.reshape(-1)  # [batch*(seq_len-1)]\n",
    "            )\n",
    "            loss_per_token = loss_per_token.reshape(targets.shape)  # [batch, seq_len-1]\n",
    "            \n",
    "            # Apply mask: only compute loss on answer token\n",
    "            mask = loss_mask[:, 1:]  # Align with targets\n",
    "            masked_loss = (loss_per_token * mask).sum() / mask.sum()\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            masked_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Metrics\n",
    "            total_loss += masked_loss.item()\n",
    "            \n",
    "            # Accuracy: check if predicted answer digit is correct\n",
    "            preds = logits.argmax(dim=-1)  # [batch, seq_len-1]\n",
    "            answer_positions = mask.bool()\n",
    "            if answer_positions.any():\n",
    "                correct += (preds[answer_positions] == targets[answer_positions]).sum().item()\n",
    "                total += answer_positions.sum().item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': masked_loss.item(), \n",
    "                            'acc': correct/total if total > 0 else 0})\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Loss={total_loss/len(train_loader):.4f}, \"\n",
    "              f\"Acc={correct/total:.4f}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'checkpoint-{name}-epoch-{epoch+1}.pt')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train!\n",
    "models = {}\n",
    "for name in train_dataset_names:\n",
    "    config = HookedTransformerConfig(\n",
    "            n_layers=2,\n",
    "            n_heads=8,\n",
    "            d_model=128,\n",
    "            d_head=16,  # d_model / n_heads\n",
    "            d_mlp=None,  # No MLPs (attention-only)\n",
    "            act_fn=None,  # No activation (no MLPs)\n",
    "            attention_dir=\"causal\",  # Causal attention\n",
    "            attn_only=True,  # Attention-only model\n",
    "            normalization_type=None,  # No LayerNorm for simplicity\n",
    "            d_vocab=train_tokenizers[name].vocab.size + 5,  # Total vocab size for particular tokenizer\n",
    "            n_ctx=100,  # Max sequence length\n",
    "            init_weights=True,\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "    model = HookedTransformer(config)\n",
    "    if RETRAIN:\n",
    "        print(f\"Starting to train model for {name} with vocab size {train_tokenizers[name].vocab.size}\")\n",
    "        models[name] = train_model(model, name, train_loaders[name], n_epochs=20, lr=1e-3)\n",
    "    else:\n",
    "        checkpoint = torch.load(f'checkpoint-{name}-epoch-100.pt', map_location=\"cpu\")\n",
    "        \n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        models[name] = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7ef2db7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model easy accuracy on easy: 1.0\n",
      "Testing model bpe-hard accuracy on bpe-hard: 0.5165\n",
      "Testing model mult-hard accuracy on mult-hard: 0.949\n",
      "Testing model length-hard accuracy on length-hard: 0.5105\n",
      "Testing model all-hard accuracy on all-hard: 0.1565\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'mixed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Test\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m train_dataset_names:\n\u001b[32m     42\u001b[39m     accuracy = evaluate_model(models[name], DataLoader(\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m         \u001b[43mtest_datasets\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[32m     44\u001b[39m         batch_size=\u001b[32m64\u001b[39m,\n\u001b[32m     45\u001b[39m         shuffle=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     46\u001b[39m         collate_fn=collate_fn\n\u001b[32m     47\u001b[39m     ))\n\u001b[32m     48\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTesting model \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m accuracy on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maccuracy\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: 'mixed'"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            loss_mask = batch[\"loss_mask\"].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(input_ids[:, :-1])\n",
    "            targets = input_ids[:, 1:]\n",
    "            mask = loss_mask[:, 1:]\n",
    "            \n",
    "            # Get predictions\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            \n",
    "            # Identify valid rows\n",
    "            per_row = mask.sum(dim=1)\n",
    "            valid_rows = (per_row == 1)\n",
    "            \n",
    "            if not valid_rows.any():\n",
    "                continue   # skip batches with no valid rows\n",
    "            \n",
    "            # Filter only valid rows\n",
    "            mask_valid = mask[valid_rows].bool()\n",
    "            preds_valid = preds[valid_rows]\n",
    "            targets_valid = targets[valid_rows]\n",
    "            \n",
    "            # Extract predictions and true labels at masked positions\n",
    "            pred_answers = preds_valid[mask_valid]\n",
    "            true_answers = targets_valid[mask_valid]\n",
    "            \n",
    "            correct += (pred_answers == true_answers).sum().item()\n",
    "            total += pred_answers.numel()\n",
    "            \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Test\n",
    "for name in train_dataset_names:\n",
    "    accuracy = evaluate_model(models[name], DataLoader(\n",
    "        test_datasets[name],\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    ))\n",
    "    print(f\"Testing model {name} accuracy on {name}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49abf8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
