{
 "cells": [
  {
   "cell_type": "raw",
   "id": "73cb6f89-0245-42ae-9f4d-be62cadc2d83",
   "metadata": {},
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5edb4bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters: 152,626\n",
      "Model device: cuda:0\n",
      "Model device name: NVIDIA GeForce RTX 4080 SUPER\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig\n",
    "\n",
    "# Configuration\n",
    "config = HookedTransformerConfig(\n",
    "    n_layers=2,\n",
    "    n_heads=8,\n",
    "    d_model=128,\n",
    "    d_head=16,  # d_model / n_heads\n",
    "    d_mlp=None,  # No MLPs (attention-only)\n",
    "    act_fn=None,  # No activation (no MLPs)\n",
    "    attention_dir=\"causal\",  # Causal attention\n",
    "    attn_only=True,  # Attention-only model\n",
    "    normalization_type=None,  # No LayerNorm for simplicity\n",
    "    d_vocab=50,  # 26 letters + 10 digits + special tokens\n",
    "    n_ctx=60,  # Max sequence length\n",
    "    init_weights=True,\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "model = HookedTransformer(config)\n",
    "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "print(f\"Model device name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65d59195-2df3-4d0c-bf1d-bce5105aa3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vocabulary:\n",
    "    class TrieNode:\n",
    "        def __init__(self):\n",
    "            self.id = None\n",
    "            self.next = {}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.root = self.TrieNode()\n",
    "        self.token_map = {} # Stores mapping of ID to token\n",
    "        self.size = 0\n",
    "\n",
    "    # Adds a new token into the vocabulary\n",
    "    def add_token(self, token):\n",
    "        node = self.root\n",
    "        for c in token:\n",
    "            if c not in node.next:\n",
    "                node.next[c] = self.TrieNode()\n",
    "            node = node.next[c]\n",
    "        if node.id is None:\n",
    "            node.id = self.size\n",
    "            self.token_map[self.size] = token\n",
    "            self.size += 1\n",
    "\n",
    "    # Finds id of longest prefix token of text[start:end], and returns length of token\n",
    "    def longest_prefix_token(self, text, start):\n",
    "        longest_token = None\n",
    "        longest_length = 0\n",
    "        node = self.root\n",
    "        for i in range(start, len(text)):\n",
    "            if text[i] not in node.next:\n",
    "                break\n",
    "            node = node.next[text[i]]\n",
    "            if node.id is not None:\n",
    "                longest_token = node.id\n",
    "                longest_length = i - start + 1\n",
    "        assert longest_token is not None\n",
    "        return longest_token, longest_length\n",
    "\n",
    "    # Converts an id to the corresponding token\n",
    "    def get_token(self, id):\n",
    "        return self.token_map[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f64205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple character-level tokenizer\n",
    "class CountingTokenizer:\n",
    "    def __init__(self):\n",
    "        # Vocabulary: letters + digits + special tokens\n",
    "        self.vocab = Vocabulary()\n",
    "        chars = list(\"abcdefghijklmnopqrstuvwxyz0123456789\")\n",
    "        special = [\"<PAD>\", \"<BOS>\", \"<EOS>\", \":\", \" \", \"Count\", \"the\", \"letter\", \"in\"]\n",
    "        raw_vocab = special + chars\n",
    "        for token in raw_vocab:\n",
    "            self.vocab.add_token(token)\n",
    "\n",
    "    def encode(self, text, include_lengths = False):\n",
    "        \"\"\"Convert text to token IDs\"\"\"\n",
    "        ids = []\n",
    "        i = 0\n",
    "        while i < len(text):\n",
    "            id, token_length = self.vocab.longest_prefix_token(text, i)\n",
    "            assert id != -1\n",
    "            if include_lengths:\n",
    "                ids.append((id, token_length))\n",
    "            else:\n",
    "                ids.append(id)\n",
    "            i += token_length\n",
    "        return ids\n",
    "    \n",
    "    def decode(self, ids):\n",
    "        \"\"\"Convert token IDs to text\"\"\"\n",
    "        return \"\".join([self.vocab.get_token(id) for id in ids])\n",
    "\n",
    "    def apply_bpe(self, words, max_token_length=3):\n",
    "        \"\"\"Adds merge rules based on a list of words for BPE\"\"\"\n",
    "        text = \"\".join([f\"<BOS>{word}<EOS>\" for word in words])\n",
    "        ignore_tokens = [\"<PAD>\", \"<BOS>\", \"<EOS>\", \":\", \" \"]\n",
    "        while True:\n",
    "            encoded = self.encode(text, include_lengths=True)\n",
    "            pairs = {}\n",
    "            merge_pair = ()\n",
    "            for i in range(len(encoded) - 1):\n",
    "                token_pair = encoded[i], encoded[i + 1]\n",
    "                if token_pair[0][1] + token_pair[1][1] > max_token_length:\n",
    "                    continue\n",
    "                if any(self.vocab.get_token(token[0]) in ignore_tokens for token in token_pair):\n",
    "                    continue\n",
    "                pairs[token_pair] = pairs.get(token_pair, 0) + 1\n",
    "                if not merge_pair or pairs[merge_pair] < pairs[token_pair]:\n",
    "                    merge_pair = token_pair\n",
    "            if not merge_pair or pairs[merge_pair] < 2:\n",
    "                break\n",
    "            self.vocab.add_token(\"\".join([self.vocab.get_token(token[0]) for token in merge_pair]))\n",
    "\n",
    "tokenizer = CountingTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8fbf56ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Count the letter a in: atlga2\n",
      "Tokens: [5, 4, 6, 4, 7, 4, 9, 4, 8, 3, 4, 9, 28, 20, 15, 9, 37]\n",
      "Question Tokens Decoded: ['Count', ' ', 'the', ' ', 'letter', ' ', 'a', ' ', 'in', ':', ' ', 'a', 't', 'l', 'g', 'a']\n",
      "Question length: 16\n",
      "Answer: 2\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_counting_question(target_letter='a', multiplicity_range=(1, 2), length_range=(5, 10)):\n",
    "    \"\"\"\n",
    "    Generates a new word based on input parameters and gives the answer to the question\n",
    "    \"\"\"\n",
    "    \n",
    "    # Sample words with target letter\n",
    "    words_with_target = []\n",
    "    count = random.randint(*multiplicity_range)\n",
    "    \n",
    "    # Generate string with exact count of target letter\n",
    "    chars = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "    chars.remove(target_letter)\n",
    "    \n",
    "    length = random.randint(max(count, length_range[0]), length_range[1])\n",
    "    string_chars = random.choices(chars, k=length - count)\n",
    "    \n",
    "    # Insert target letters\n",
    "    positions = random.sample(range(length), count)\n",
    "    for pos in positions:\n",
    "        string_chars.insert(pos, target_letter)\n",
    "    \n",
    "    input_string = \"\".join(string_chars[:length])\n",
    "    question = f\"Count the letter {target_letter} in: {input_string}\"\n",
    "    answer = str(count)\n",
    "\n",
    "    return question, answer\n",
    "\n",
    "def generate_counting_example(qa, tokenizer=None):\n",
    "    \"\"\"\n",
    "    Generate: \"Count the letter a in: banana\" -> \"3\"\n",
    "    Format: [question tokens] [answer token]\n",
    "    \"\"\"\n",
    "    question, answer = qa\n",
    "    \n",
    "    # Tokenize\n",
    "    question_tokens = tokenizer.encode(question)\n",
    "    question_tokens_decoded = [tokenizer.decode([token]) for token in question_tokens]\n",
    "    answer_token = tokenizer.encode(answer)[0]  # Single digit\n",
    "    \n",
    "    # Combine: question + answer\n",
    "    full_tokens = question_tokens + [answer_token]\n",
    "    \n",
    "    return {\n",
    "        'tokens': full_tokens,\n",
    "        'question_tokens_decoded': question_tokens_decoded,\n",
    "        'question_length': len(question_tokens),  # For loss masking\n",
    "        'answer': int(answer),\n",
    "        'text': question + answer\n",
    "    }\n",
    "\n",
    "# Test\n",
    "tokenizer = CountingTokenizer()\n",
    "qa = generate_counting_question()\n",
    "example = generate_counting_example(qa, tokenizer=tokenizer)\n",
    "print(f\"Text: {example['text']}\")\n",
    "print(f\"Tokens: {example['tokens']}\")\n",
    "print(f\"Question Tokens Decoded: {example['question_tokens_decoded']}\")\n",
    "print(f\"Question length: {example['question_length']}\")\n",
    "print(f\"Answer: {example['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "096c9875-c66d-48e8-8b77-a82023f79280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Pre-Processing Text: <BOS>Count the letter a in: raylqa<EOS><BOS>Count the letter a in: ajiwuiblik<EOS><BOS>Count the letter a in: jfaqswallk<EOS><BOS>Count the letter a in: imaqa<EOS><BOS>Count the letter a in: zsvaa<EOS><BOS>Count the letter a in: rznxdurabr<EOS><BOS>Count the letter a in: acqqay<EOS><BOS>Count the letter a in: lrhdabiac<EOS><BOS>Count the letter a in: ayancrgik<EOS><BOS>Count the letter a in: redhoeafq<EOS>\n",
      "Text: Count the letter a in: ucfxkal1\n",
      "Tokens: [5, 4, 6, 4, 7, 4, 9, 4, 8, 3, 4, 29, 11, 14, 32, 19, 9, 20, 36]\n",
      "Question Tokens Decoded: ['Count', ' ', 'the', ' ', 'letter', ' ', 'a', ' ', 'in', ':', ' ', 'u', 'c', 'f', 'x', 'k', 'a', 'l']\n",
      "Question length: 18\n",
      "Answer: 1\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "qas = [generate_counting_question() for i in range(10)]\n",
    "tokenizer = CountingTokenizer()\n",
    "tokenizer.apply_bpe([qa[0] for qa in qas])\n",
    "qa = generate_counting_question()\n",
    "example = generate_counting_example(qa, tokenizer=tokenizer)\n",
    "print(f\"Sample Pre-Processing Text: {\"\".join([f\"<BOS>{qa[0]}<EOS>\" for qa in qas])}\")\n",
    "print(f\"Text: {example['text']}\")\n",
    "print(f\"Tokens: {example['tokens']}\")\n",
    "print(f\"Question Tokens Decoded: {example['question_tokens_decoded']}\")\n",
    "print(f\"Question length: {example['question_length']}\")\n",
    "print(f\"Answer: {example['answer']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "973f38a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "3004\n",
      "45\n",
      "45\n",
      "3588\n",
      "3785\n",
      "Input shape: torch.Size([64, 17])\n",
      "Mask shape: torch.Size([64, 17])\n",
      "Example tokens: tensor([  5,   4,   6,   4,   7,   4,  18,   4,   8,   3,   4, 153, 194, 169,\n",
      "         37,   0,   0])\n",
      "Example mask: tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "GENERATE_NEW_TRAINING_DATA = False # IMPORTANT: Set this to True only if you want to generate new datasets\n",
    "\n",
    "class CountingDataset(Dataset):\n",
    "    def __init__(self, n_examples=50000, difficulty='easy', tokenizer=None, allow_bpe=True):\n",
    "        \"\"\"\n",
    "        difficulty: 'easy', 'bpe-hard', 'mult-hard', etc.\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.examples = []\n",
    "\n",
    "        use_bpe = False\n",
    "        # Set parameters based on difficulty\n",
    "        if difficulty == 'easy':\n",
    "            mult_range = (1, 2)\n",
    "            len_range = (5, 10)\n",
    "        elif difficulty == 'bpe-hard':\n",
    "            mult_range = (1, 2)\n",
    "            len_range = (5, 10)\n",
    "            use_bpe = True\n",
    "        elif difficulty == 'mult-hard':\n",
    "            mult_range = (3, 10)\n",
    "            len_range = (5, 10)\n",
    "        elif difficulty == 'length-hard':\n",
    "            mult_range = (1, 2)\n",
    "            len_range = (20, 50)\n",
    "        elif difficulty == 'all-hard':\n",
    "            mult_range = (3, 10)\n",
    "            len_range = (20, 50)\n",
    "            use_bpe = True\n",
    "        elif difficulty == 'mixed':\n",
    "            mult_range = (1,10)\n",
    "            len_range = (5, 50)\n",
    "            use_bpe = True\n",
    "        else:\n",
    "            assert False\n",
    "        \n",
    "        # Generate basic words\n",
    "        target_letters = list(\"abcdefghijklmnopqrstuvwxyz\")\n",
    "        qas = []\n",
    "        for _ in range(n_examples):\n",
    "            target = random.choice(target_letters)\n",
    "            qa = generate_counting_question(\n",
    "                target_letter=target,\n",
    "                multiplicity_range=mult_range,\n",
    "                length_range=len_range,\n",
    "            )\n",
    "            qas.append(qa)\n",
    "\n",
    "        # Add basic words to the vocabulary if we are applying BPE\n",
    "        if use_bpe and allow_bpe:\n",
    "            tokenizer.apply_bpe([qa[0] for qa in qas])\n",
    "\n",
    "        # Generate the full questions and examples\n",
    "        basic_tokenizer = CountingTokenizer()\n",
    "        if difficulty == \"mixed\":\n",
    "            bpe_set = random.sample(range(len(qas)), len(qas) // 2)\n",
    "        else:\n",
    "            bpe_set = range(len(qas))\n",
    "        for i in range(len(qas)):\n",
    "            example = generate_counting_example(\n",
    "                qas[i],\n",
    "                tokenizer=tokenizer if i in bpe_set else basic_tokenizer\n",
    "            )\n",
    "            self.examples.append(example)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.examples[idx]\n",
    "\n",
    "def collate_fn(batch, pad_id=0, max_len=60):\n",
    "    \"\"\"Pad sequences to same length\"\"\"\n",
    "    # Pad tokens\n",
    "    tokens = [ex['tokens'] for ex in batch]\n",
    "    max_batch_len = min(max(len(t) for t in tokens), max_len)\n",
    "    \n",
    "    padded_tokens = []\n",
    "    masks = []  # Loss mask: 1 for answer token, 0 elsewhere\n",
    "    \n",
    "    for ex in batch:\n",
    "        seq = ex['tokens'][:max_batch_len]\n",
    "        q_len = min(ex['question_length'], max_batch_len - 1)\n",
    "        \n",
    "        # Pad sequence\n",
    "        padded = seq + [pad_id] * (max_batch_len - len(seq))\n",
    "        padded_tokens.append(padded)\n",
    "        \n",
    "        # Create mask: only compute loss on answer token\n",
    "        mask = [0] * max_batch_len\n",
    "        if q_len < len(seq):  # If answer token exists\n",
    "            mask[q_len] = 1  # Answer is right after question\n",
    "        masks.append(mask)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': torch.tensor(padded_tokens, dtype=torch.long),\n",
    "        'loss_mask': torch.tensor(masks, dtype=torch.float),\n",
    "        'answers': torch.tensor([ex['answer'] for ex in batch], dtype=torch.long)\n",
    "    }\n",
    "\n",
    "# Create dataloaders\n",
    "train_dataset_names = [\"easy\", \"bpe-hard\", \"mult-hard\", \"length-hard\", \"all-hard\", \"mixed\"]\n",
    "\n",
    "# Training dataloaders\n",
    "train_datasets = {}\n",
    "train_loaders = {}\n",
    "train_tokenizers = {}\n",
    "for name in train_dataset_names:\n",
    "    if GENERATE_NEW_TRAINING_DATA:\n",
    "        train_tokenizers[name] = CountingTokenizer()\n",
    "        train_datasets[name] = CountingDataset(n_examples=20000, difficulty=name, tokenizer=train_tokenizers[name])\n",
    "        with open(f\"train-{name}-dataset.pkl\", \"wb\") as f:\n",
    "            pickle.dump(train_datasets[name], f)\n",
    "        with open(f\"train-{name}-tokenizer.pkl\", \"wb\") as f:\n",
    "            pickle.dump(train_tokenizers[name], f)\n",
    "    else:\n",
    "        with open(f\"train-{name}-dataset.pkl\", \"rb\") as f:\n",
    "            train_datasets[name] = pickle.load(f)\n",
    "        with open(f\"train-{name}-tokenizer.pkl\", \"rb\") as f:\n",
    "            train_tokenizers[name] = pickle.load(f)\n",
    "            print(train_tokenizers[name].vocab.size)\n",
    "    train_loaders[name] = DataLoader(train_datasets[name], batch_size=64, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# Test batch\n",
    "batch = next(iter(train_loaders[\"bpe-hard\"]))\n",
    "print(f\"Input shape: {batch['input_ids'].shape}\")\n",
    "print(f\"Mask shape: {batch['loss_mask'].shape}\")\n",
    "print(f\"Example tokens: {batch['input_ids'][0]}\")\n",
    "print(f\"Example mask: {batch['loss_mask'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5241ff67-7c6a-4c23-b58f-2f1ca79e73f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATE_NEW_TESTING_DATA = False # IMPORTANT: Set this to True only if you want to generate new datasets\n",
    "\n",
    "# Testing dataloaders\n",
    "test_dataset_names = [\"easy\", \"bpe-hard\", \"mult-hard\", \"length-hard\", \"all-hard\", \"mixed\"]\n",
    "test_datasets = {}\n",
    "test_tokenizers = {}\n",
    "for name in test_dataset_names:\n",
    "    if GENERATE_NEW_TESTING_DATA:\n",
    "        test_datasets[name] = CountingDataset(n_examples=2000, difficulty=name, tokenizer=train_tokenizers[name], allow_bpe=False)\n",
    "        with open(f\"test-{name}-dataset.pkl\", \"wb\") as f:\n",
    "            pickle.dump(test_datasets[name], f)\n",
    "    else:\n",
    "        with open(f\"test-{name}-dataset.pkl\", \"rb\") as f:\n",
    "            test_datasets[name] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fa2db8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train model for easy with vocab size 45\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 263.14it/s, loss=0.698, acc=0.493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.7930, Acc=0.4929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 298.67it/s, loss=0.683, acc=0.507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=0.6968, Acc=0.5070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 295.75it/s, loss=0.706, acc=0.502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.6975, Acc=0.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 294.91it/s, loss=0.693, acc=0.504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.6969, Acc=0.5036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|███████████████████████████████████| 313/313 [00:01<00:00, 292.31it/s, loss=0.7, acc=0.504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.6955, Acc=0.5037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 296.90it/s, loss=0.655, acc=0.539]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.6896, Acc=0.5386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 297.79it/s, loss=0.636, acc=0.591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.6684, Acc=0.5906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 299.02it/s, loss=0.545, acc=0.657]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.6114, Acc=0.6573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 297.75it/s, loss=0.632, acc=0.848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.3431, Acc=0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|███████████████████████████████| 313/313 [00:01<00:00, 303.43it/s, loss=0.0194, acc=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.0591, Acc=0.9805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|███████████████████████████████| 313/313 [00:01<00:00, 297.59it/s, loss=0.0135, acc=0.997]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.0134, Acc=0.9970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|█████████████████████████████| 313/313 [00:01<00:00, 297.35it/s, loss=0.000513, acc=0.999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.0088, Acc=0.9985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|█████████████████████████████| 313/313 [00:01<00:00, 304.04it/s, loss=0.000976, acc=0.998]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.0076, Acc=0.9983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|█████████████████████████████| 313/313 [00:01<00:00, 301.08it/s, loss=0.000181, acc=0.999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.0050, Acc=0.9990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|███████████████████████████████| 313/313 [00:01<00:00, 292.03it/s, loss=0.0156, acc=0.999]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.0026, Acc=0.9994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 293.93it/s, loss=0.000146, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.0019, Acc=0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 303.09it/s, loss=0.000246, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.0016, Acc=0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 303.30it/s, loss=0.000134, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.0010, Acc=0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 300.28it/s, loss=0.000586, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.0008, Acc=0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 300.98it/s, loss=5.94e-5, acc=1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.0006, Acc=0.9999\n",
      "Starting to train model for bpe-hard with vocab size 3004\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 299.79it/s, loss=0.743, acc=0.49]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=0.9627, Acc=0.4904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 301.80it/s, loss=0.794, acc=0.553]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=0.6829, Acc=0.5532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 301.04it/s, loss=0.699, acc=0.588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.6586, Acc=0.5877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 302.07it/s, loss=0.706, acc=0.626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.6206, Acc=0.6260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 301.00it/s, loss=0.679, acc=0.66]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.5797, Acc=0.6602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 288.26it/s, loss=0.577, acc=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.5453, Acc=0.6894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 297.71it/s, loss=0.567, acc=0.72]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.5057, Acc=0.7201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 304.25it/s, loss=0.549, acc=0.753]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.4603, Acc=0.7526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 297.00it/s, loss=0.323, acc=0.789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.4093, Acc=0.7892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 300.82it/s, loss=0.347, acc=0.817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.3611, Acc=0.8171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 296.37it/s, loss=0.247, acc=0.848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.3126, Acc=0.8482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 298.80it/s, loss=0.385, acc=0.873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.2682, Acc=0.8729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 292.64it/s, loss=0.176, acc=0.896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.2265, Acc=0.8962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 304.90it/s, loss=0.284, acc=0.912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.1961, Acc=0.9121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 301.64it/s, loss=0.258, acc=0.928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.1640, Acc=0.9285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 302.63it/s, loss=0.168, acc=0.941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.1383, Acc=0.9411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 295.25it/s, loss=0.148, acc=0.952]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.1184, Acc=0.9522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|███████████████████████████████| 313/313 [00:01<00:00, 297.19it/s, loss=0.0662, acc=0.958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.1048, Acc=0.9578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 296.18it/s, loss=0.137, acc=0.962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.0970, Acc=0.9622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 299.40it/s, loss=0.074, acc=0.965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.0929, Acc=0.9647\n",
      "Starting to train model for mult-hard with vocab size 45\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 302.19it/s, loss=1.76, acc=0.244]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=1.9294, Acc=0.2440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|███████████████████████████████████| 313/313 [00:01<00:00, 309.63it/s, loss=1.5, acc=0.304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=1.7141, Acc=0.3044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 306.84it/s, loss=0.893, acc=0.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=1.2792, Acc=0.4603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 297.26it/s, loss=0.689, acc=0.613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.9090, Acc=0.6128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 294.92it/s, loss=0.486, acc=0.68]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.7476, Acc=0.6796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 292.11it/s, loss=0.625, acc=0.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.6306, Acc=0.7382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 298.61it/s, loss=0.473, acc=0.765]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.5554, Acc=0.7646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 293.90it/s, loss=0.355, acc=0.799]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.4800, Acc=0.7986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|███████████████████████████████████| 313/313 [00:01<00:00, 293.54it/s, loss=0.4, acc=0.827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.4207, Acc=0.8270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 297.41it/s, loss=0.327, acc=0.858]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.3573, Acc=0.8576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 297.25it/s, loss=0.454, acc=0.882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.2958, Acc=0.8824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 304.55it/s, loss=0.503, acc=0.903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.2474, Acc=0.9033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 301.57it/s, loss=0.138, acc=0.918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.2120, Acc=0.9181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|███████████████████████████████| 313/313 [00:01<00:00, 295.43it/s, loss=0.0842, acc=0.936]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.1749, Acc=0.9358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|███████████████████████████████| 313/313 [00:01<00:00, 296.24it/s, loss=0.0739, acc=0.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.1508, Acc=0.9450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 298.43it/s, loss=0.125, acc=0.956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.1275, Acc=0.9565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 295.29it/s, loss=0.158, acc=0.963]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.1104, Acc=0.9625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|███████████████████████████████| 313/313 [00:01<00:00, 303.06it/s, loss=0.0651, acc=0.966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.1003, Acc=0.9664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 300.61it/s, loss=0.0581, acc=0.97]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.0935, Acc=0.9697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 294.59it/s, loss=0.13, acc=0.971]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.0898, Acc=0.9713\n",
      "Starting to train model for length-hard with vocab size 45\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 280.53it/s, loss=1.11, acc=0.467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=1.0543, Acc=0.4669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 282.26it/s, loss=0.861, acc=0.473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=0.9134, Acc=0.4728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 279.05it/s, loss=0.733, acc=0.478]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=0.9101, Acc=0.4780\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 281.40it/s, loss=0.866, acc=0.471]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=0.9072, Acc=0.4708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|███████████████████████████████████| 313/313 [00:01<00:00, 276.05it/s, loss=1.07, acc=0.48]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=0.9060, Acc=0.4797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 282.51it/s, loss=1.05, acc=0.476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=0.9038, Acc=0.4761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 278.17it/s, loss=0.931, acc=0.473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=0.9026, Acc=0.4734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 274.21it/s, loss=1.15, acc=0.487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=0.8984, Acc=0.4867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 280.25it/s, loss=0.867, acc=0.475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.8967, Acc=0.4748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 280.93it/s, loss=0.774, acc=0.483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.8944, Acc=0.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 288.32it/s, loss=0.995, acc=0.487]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.8899, Acc=0.4867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 275.37it/s, loss=0.807, acc=0.485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.8869, Acc=0.4849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 280.26it/s, loss=0.868, acc=0.483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.8824, Acc=0.4834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 276.66it/s, loss=1.07, acc=0.486]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.8787, Acc=0.4856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 276.39it/s, loss=0.909, acc=0.493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.8719, Acc=0.4929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 275.70it/s, loss=0.921, acc=0.496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.8667, Acc=0.4962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 285.24it/s, loss=0.999, acc=0.494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.8633, Acc=0.4944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 282.11it/s, loss=0.902, acc=0.496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.8602, Acc=0.4963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 277.93it/s, loss=0.751, acc=0.501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.8577, Acc=0.5007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 281.50it/s, loss=0.897, acc=0.502]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.8572, Acc=0.5017\n",
      "Starting to train model for all-hard with vocab size 3588\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 286.22it/s, loss=2.14, acc=0.132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=2.3563, Acc=0.1321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 280.25it/s, loss=2.03, acc=0.194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=2.0230, Acc=0.1943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 288.33it/s, loss=1.95, acc=0.262]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=1.9002, Acc=0.2616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 293.36it/s, loss=1.61, acc=0.319]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=1.7826, Acc=0.3192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 293.25it/s, loss=2.02, acc=0.383]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=1.6157, Acc=0.3830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 288.35it/s, loss=1.59, acc=0.465]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=1.4270, Acc=0.4652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 286.88it/s, loss=1.35, acc=0.532]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=1.2646, Acc=0.5321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 287.07it/s, loss=1.13, acc=0.586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=1.1229, Acc=0.5863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 287.24it/s, loss=1.33, acc=0.642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=0.9932, Acc=0.6422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 285.83it/s, loss=1.27, acc=0.689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=0.8773, Acc=0.6888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 284.22it/s, loss=1.23, acc=0.738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=0.7535, Acc=0.7380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 288.17it/s, loss=0.871, acc=0.786]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=0.6344, Acc=0.7861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 283.86it/s, loss=0.77, acc=0.83]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=0.5204, Acc=0.8295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 286.62it/s, loss=0.539, acc=0.87]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=0.4208, Acc=0.8702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 289.55it/s, loss=0.318, acc=0.9]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=0.3358, Acc=0.8998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 284.98it/s, loss=0.316, acc=0.925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=0.2710, Acc=0.9247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 290.26it/s, loss=0.191, acc=0.941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=0.2259, Acc=0.9405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 290.92it/s, loss=0.104, acc=0.951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=0.1955, Acc=0.9505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 287.92it/s, loss=0.093, acc=0.955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=0.1781, Acc=0.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|███████████████████████████████| 313/313 [00:01<00:00, 292.54it/s, loss=0.0807, acc=0.958]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=0.1698, Acc=0.9580\n",
      "Starting to train model for mixed with vocab size 3785\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 221.65it/s, loss=2.28, acc=0.181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss=2.5569, Acc=0.1807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 225.05it/s, loss=2.14, acc=0.194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss=2.2141, Acc=0.1937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 224.51it/s, loss=2.08, acc=0.212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss=2.1414, Acc=0.2125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 224.77it/s, loss=1.89, acc=0.268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss=2.0274, Acc=0.2676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20: 100%|████████████████████████████████████| 313/313 [00:01<00:00, 223.80it/s, loss=1.7, acc=0.33]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss=1.8545, Acc=0.3296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 225.97it/s, loss=1.76, acc=0.393]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss=1.6842, Acc=0.3930\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 220.22it/s, loss=1.24, acc=0.454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss=1.5317, Acc=0.4543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 223.69it/s, loss=1.77, acc=0.499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss=1.4090, Acc=0.4988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20: 100%|███████████████████████████████████| 313/313 [00:01<00:00, 223.92it/s, loss=1.03, acc=0.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss=1.3124, Acc=0.5305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 224.40it/s, loss=1.27, acc=0.554]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss=1.2429, Acc=0.5541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 222.46it/s, loss=1.08, acc=0.574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Loss=1.1813, Acc=0.5741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20: 100%|██████████████████████████████████| 313/313 [00:01<00:00, 223.87it/s, loss=1.1, acc=0.588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Loss=1.1441, Acc=0.5882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 221.74it/s, loss=1.37, acc=0.596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Loss=1.1192, Acc=0.5958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 222.63it/s, loss=0.935, acc=0.601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Loss=1.0918, Acc=0.6006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 223.31it/s, loss=0.834, acc=0.609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Loss=1.0762, Acc=0.6093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 223.72it/s, loss=0.89, acc=0.612]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Loss=1.0631, Acc=0.6124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20: 100%|████████████████████████████████████| 313/313 [00:01<00:00, 226.63it/s, loss=1, acc=0.615]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Loss=1.0535, Acc=0.6151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 222.92it/s, loss=0.759, acc=0.617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Loss=1.0440, Acc=0.6172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20: 100%|████████████████████████████████| 313/313 [00:01<00:00, 223.71it/s, loss=0.942, acc=0.619]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Loss=1.0380, Acc=0.6193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20: 100%|█████████████████████████████████| 313/313 [00:01<00:00, 223.22it/s, loss=1.04, acc=0.621]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Loss=1.0353, Acc=0.6210\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "RETRAIN = False # IMPORTANT: Only toggle to True if you want to actually train new models\n",
    "\n",
    "def train_model(model, name, train_loader, n_epochs=10, lr=1e-3, device='cuda'):\n",
    "    \"\"\"\n",
    "    Train with MASKED loss (only on answer token)\n",
    "    \n",
    "    Classification loss: CrossEntropy on vocabulary\n",
    "    (Can also try regression loss on digit value)\n",
    "    \"\"\"\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=n_epochs)\n",
    "    \n",
    "    # Classification loss (predict token ID)\n",
    "    criterion = nn.CrossEntropyLoss(reduction='none')  # Per-token loss\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{n_epochs}\")\n",
    "        for batch in pbar:\n",
    "            input_ids = batch['input_ids'].to(device)  # [batch, seq_len]\n",
    "            loss_mask = batch['loss_mask'].to(device)  # [batch, seq_len]\n",
    "            \n",
    "            # Forward pass\n",
    "            # Input: all tokens except last\n",
    "            # Target: all tokens except first (shifted by 1)\n",
    "            logits = model(input_ids[:, :-1])  # [batch, seq_len-1, vocab]\n",
    "            targets = input_ids[:, 1:]  # [batch, seq_len-1]\n",
    "            \n",
    "            # Compute loss\n",
    "            loss_per_token = criterion(\n",
    "                logits.reshape(-1, logits.size(-1)),  # [batch*(seq_len-1), vocab]\n",
    "                targets.reshape(-1)  # [batch*(seq_len-1)]\n",
    "            )\n",
    "            loss_per_token = loss_per_token.reshape(targets.shape)  # [batch, seq_len-1]\n",
    "            \n",
    "            # Apply mask: only compute loss on answer token\n",
    "            mask = loss_mask[:, 1:]  # Align with targets\n",
    "            masked_loss = (loss_per_token * mask).sum() / mask.sum()\n",
    "            \n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            masked_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Metrics\n",
    "            total_loss += masked_loss.item()\n",
    "            \n",
    "            # Accuracy: check if predicted answer digit is correct\n",
    "            preds = logits.argmax(dim=-1)  # [batch, seq_len-1]\n",
    "            answer_positions = mask.bool()\n",
    "            if answer_positions.any():\n",
    "                correct += (preds[answer_positions] == targets[answer_positions]).sum().item()\n",
    "                total += answer_positions.sum().item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': masked_loss.item(), \n",
    "                            'acc': correct/total if total > 0 else 0})\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Loss={total_loss/len(train_loader):.4f}, \"\n",
    "              f\"Acc={correct/total:.4f}\")\n",
    "        \n",
    "        # Save checkpoint\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "            }, f'checkpoint-{name}-epoch-{epoch+1}.pt')\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Train!\n",
    "models = {}\n",
    "for name in train_dataset_names:\n",
    "    config = HookedTransformerConfig(\n",
    "            n_layers=2,\n",
    "            n_heads=8,\n",
    "            d_model=128,\n",
    "            d_head=16,  # d_model / n_heads\n",
    "            d_mlp=None,  # No MLPs (attention-only)\n",
    "            act_fn=None,  # No activation (no MLPs)\n",
    "            attention_dir=\"causal\",  # Causal attention\n",
    "            attn_only=True,  # Attention-only model\n",
    "            normalization_type=None,  # No LayerNorm for simplicity\n",
    "            d_vocab=train_tokenizers[name].vocab.size + 5,  # Total vocab size for particular tokenizer\n",
    "            n_ctx=60,  # Max sequence length\n",
    "            init_weights=True,\n",
    "            device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        )\n",
    "    model = HookedTransformer(config)\n",
    "    if RETRAIN:\n",
    "        print(f\"Starting to train model for {name} with vocab size {train_tokenizers[name].vocab.size}\")\n",
    "        models[name] = train_model(model, name, train_loaders[name], n_epochs=20, lr=1e-3)\n",
    "    else:\n",
    "        checkpoint = torch.load(f'checkpoint-{name}-epoch-100.pt', map_location=\"cpu\")\n",
    "        \n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        models[name] = model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ef2db7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model easy accuracy on easy: 0.9985\n",
      "Testing model bpe-hard accuracy on bpe-hard: 0.519\n",
      "Testing model mult-hard accuracy on mult-hard: 0.9315\n",
      "Testing model length-hard accuracy on length-hard: 0.4795\n",
      "Testing model all-hard accuracy on all-hard: 0.182\n",
      "Testing model mixed accuracy on mixed: 0.158\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataloader, device='cuda'):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            loss_mask = batch[\"loss_mask\"].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            logits = model(input_ids[:, :-1])\n",
    "            targets = input_ids[:, 1:]\n",
    "            mask = loss_mask[:, 1:]\n",
    "            \n",
    "            # Get predictions\n",
    "            preds = logits.argmax(dim=-1)\n",
    "            \n",
    "            # Identify valid rows\n",
    "            per_row = mask.sum(dim=1)\n",
    "            valid_rows = (per_row == 1)\n",
    "            \n",
    "            if not valid_rows.any():\n",
    "                continue   # skip batches with no valid rows\n",
    "            \n",
    "            # Filter only valid rows\n",
    "            mask_valid = mask[valid_rows].bool()\n",
    "            preds_valid = preds[valid_rows]\n",
    "            targets_valid = targets[valid_rows]\n",
    "            \n",
    "            # Extract predictions and true labels at masked positions\n",
    "            pred_answers = preds_valid[mask_valid]\n",
    "            true_answers = targets_valid[mask_valid]\n",
    "            \n",
    "            correct += (pred_answers == true_answers).sum().item()\n",
    "            total += pred_answers.numel()\n",
    "            \n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "# Test\n",
    "for name in train_dataset_names:\n",
    "    accuracy = evaluate_model(models[name], DataLoader(\n",
    "        test_datasets[name],\n",
    "        batch_size=64,\n",
    "        shuffle=False,\n",
    "        collate_fn=collate_fn\n",
    "    ))\n",
    "    print(f\"Testing model {name} accuracy on {name}: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a196f00-69e3-4b96-9fb3-b830125c173b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Jupyter venv)",
   "language": "python",
   "name": "jupyter-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
